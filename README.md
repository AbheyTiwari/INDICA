<h1 align="center">
  ğŸ¤– INDICA v1.0  
  <br>
  <sub><i>Intelligent Natural Dialogue Interface & Cognitive Assistant</i></sub>
</h1>

<p align="center">
  <b>A mango-rooted AI with purpose, power, and memory ğŸ‹</b>
  <br>
  <i>Created by <a href="https://github.com/AbheyTiwari">Abhey Tiwari</a></i>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python" />
  <img src="https://img.shields.io/badge/Gemini-API-green?style=for-the-badge&logo=google" />
  <img src="https://img.shields.io/badge/Voice-Controlled-Yes-purple?style=for-the-badge&logo=voicemod" />
</p>

---

## ğŸŒŸ What is INDICA?

> INDICA is your voice-powered virtual assistant that **thinks, talks, and acts** â€” combining Gemini AI, command execution, and memory into one smooth Python experience.

Originally named after the creatorâ€™s love for mangoes (*Mangifera indica* ğŸ¥­), **INDICA** now stands for:

> **I**ntelligent **N**atural **D**ialogue **I**nterface & **C**ognitive **A**ssistant  

It also pays homage to *Indica*, the legendary text by Megasthenes ğŸ‡®ğŸ‡³ğŸ“œ.

---

## âœ¨ Features

### ğŸ§  Memory System
- Stores **last 5 conversations** in `logs/logs.txt`
- Injects memory context into Gemini prompts for continuity
- Long-Term Memory support (Coming soon)

### ğŸ’¬ Voice Interaction
- Talk naturally using speech recognition ğŸ¤
- Responses are **spoken out loud** with `pyttsx3` ğŸ—£ï¸
- Can be extended to multi-user recognition

### âš™ï¸ Smart Action System
- Gemini-driven **action parsing**
- Supports:
  - `open_app`, `send_email`, `get_weather`, `play_music`, etc.
- Actions dispatched only when explicitly requested

### ğŸ” Sanity & Safety
- No hallucinated actions
- No implicit commands
- No "guessing" behavior
- Only performs what it is **clearly instructed to do**

---

## ğŸ§± Project Structure

```mermaid
flowchart TD
    %% Style definitions
    classDef user fill:#cce5ff,stroke:#003366,stroke-width:2px;
    classDef speech fill:#d4edda,stroke:#155724,stroke-width:2px;
    classDef parser fill:#fff3cd,stroke:#856404,stroke-width:2px;
    classDef decision fill:#f8d7da,stroke:#721c24,stroke-width:2px;
    classDef rag fill:#e2e3e5,stroke:#383d41,stroke-width:2px;
    classDef sys fill:#f1e0ff,stroke:#5a005a,stroke-width:2px;
    classDef tts fill:#d1ecf1,stroke:#0c5460,stroke-width:2px;
    classDef memory fill:#fefefe,stroke:#343a40,stroke-width:2px,stroke-dasharray:5 5;

    %% User
    User(["ğŸ‘¤ <b>User</b><br/>(Voice Command)"]):::user

    %% Speech to text
    STT(["ğŸ—£ï¸ <b>Speech-to-Text</b><br/>(Whisper etc.)"]):::speech

    %% Parser
    Parser(["ğŸ§© <b>Intent Recognizer</b><br/>(Command Parser)"]):::parser

    %% Decision Engine
    Decision(["âš™ï¸ <b>Decision Engine</b><br/>(Task Router)"]):::decision

    %% Tasks
    RAG(["ğŸ§  <b>Retrieval-Augmented Generator</b><br/>(LLM + Context)"]):::rag
    SysCtrl(["ğŸ–¥ï¸ <b>System Control</b><br/>(Shutdown, Open Apps)"]):::sys

    %% TTS
    TTS(["ğŸ”Š <b>Text-to-Speech</b><br/>(Voice Out)"]):::tts

    %% Memory
    subgraph Memory["ğŸ—‚ï¸ <b>Memory</b>"]
        ShortTerm(["â³ <b>Short-Term Memory</b><br/>(Current Session)"]):::memory
        LongTerm(["ğŸ—ƒï¸ <b>Long-Term Memory</b><br/>(Logs + Embeddings)"]):::memory
    end

    %% Flows
    User -->|Voice| STT
    STT -->|Text| Parser
    Parser -->|Intent| Decision
    Decision -->|Knowledge Task| RAG
    Decision -->|System Task| SysCtrl
    RAG -->|Answer| TTS
    SysCtrl -->|Confirmation| TTS
    TTS -->|Voice| User

    %% Memory connections
    Parser --> Memory
    RAG --> Memory
    SysCtrl --> Memory

    %% Note
    note over Decision
        Single Agent Architecture<br/>Voice-driven, Retrieval-Augmented
    end

```


```bash
INDICA/
â”œâ”€â”€ ai_engine/
â”‚   â””â”€â”€ gemini_engine.py     # Gemini LLM logic
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ wish.py              # Greets the user
â”‚   â”œâ”€â”€ memory.py            # Memory handling
â”‚   â””â”€â”€ ...                  # Extendable modules
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ logs.txt             # Short-term memory
â”œâ”€â”€ dispatcher.py            # Action dispatch engine
â”œâ”€â”€ listener.py              # Voice input
â”œâ”€â”€ tts.py                   # Voice output (text-to-speech)
â”œâ”€â”€ config.py                # API keys & settings
â””â”€â”€ main.py                  # Entry point to run INDICA
ğŸ”§ Installation
Clone the Repository:

bash
Copy
Edit
git clone https://github.com/AbheyTiwari/indica.git
cd indica
(Optional) Create a Virtual Environment:

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Install Dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Configure API Keys:

Create a .env file and add:

env
Copy
Edit
GEMINI_API_KEY=your_google_gemini_key
WEATHERSTACK_API_KEY=your_weather_api_key
ğŸš€ Usage
Just run the main file:

bash
Copy
Edit
python main.py
Now speak naturally. INDICA will reply and take action when applicable.

ğŸ—£ï¸ Sample Commands:
"What time is it?"

"Send an email to Rahul"

"Open Spotify"

"Get weather in Delhi"

"Tell me a joke"

"Search Python on Wikipedia"

ğŸ§° Dependencies
Includes support for:

lua
Copy
Edit
pyttsx3, speech_recognition, python-dotenv,
requests, pywhatkit, wikipedia, pyjokes,
datetime, subprocess, smtplib, webbrowser,
cv2, os, threading, winsound, re
ğŸ› ï¸ Contributing
Got an idea to make INDICA even better?

Fork the repo ğŸ´

Create a new branch ğŸ‹

Commit your changes âœï¸

Open a pull request ğŸš€

